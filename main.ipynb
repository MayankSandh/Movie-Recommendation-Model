{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from surprise import Dataset, Reader\nfrom surprise.model_selection import train_test_split\n\n# Load the movielens-100k dataset\ndata = Dataset.load_builtin('ml-100k')\n\n# Split the data into training and testing sets\ntrainset, testset = train_test_split(data, test_size=0.25, random_state=42)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-12T19:52:32.079580Z","iopub.execute_input":"2024-07-12T19:52:32.079927Z","iopub.status.idle":"2024-07-12T19:52:44.521287Z","shell.execute_reply.started":"2024-07-12T19:52:32.079896Z","shell.execute_reply":"2024-07-12T19:52:44.520473Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Dataset ml-100k could not be found. Do you want to download it? [Y/n] ","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" Y\n"},{"name":"stdout","text":"Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\nDone! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n","output_type":"stream"}]},{"cell_type":"code","source":"def run_surprise_algorithm(algo_class, algo_params, trainset, testset, verbose=True):\n    \"\"\"\n    Train and evaluate a Surprise algorithm on given datasets.\n    \n    Args:\n    algo_class: A Surprise algorithm class\n    algo_params: Dictionary of parameters for the algorithm\n    trainset: Surprise Trainset object\n    testset: Surprise Testset object\n    verbose: Boolean to control print statements\n    \n    Returns:\n    train_results, test_results: Dictionaries containing evaluation metrics\n    \"\"\"\n    start_time = datetime.now()\n    train_results = {}\n    test_results = {}\n    \n    # Initialize the algorithm with provided parameters\n    algo = algo_class(**algo_params)\n    \n    # Train the algorithm\n    if verbose:\n        print('Training the model...')\n    train_start = datetime.now()\n    algo.fit(trainset)\n    if verbose:\n        print(f'Training completed. Time taken: {datetime.now() - train_start}\\n')\n    \n    # Evaluate on training data\n    if verbose:\n        print('Evaluating on training data...')\n    train_predictions = algo.test(trainset.build_testset())\n    train_rmse = accuracy.rmse(train_predictions, verbose=False)\n    train_mae = accuracy.mae(train_predictions, verbose=False)\n    \n    train_results['rmse'] = train_rmse\n    train_results['mae'] = train_mae\n    train_results['predictions'] = train_predictions\n    \n    if verbose:\n        print(f'Training RMSE: {train_rmse}')\n        print(f'Training MAE: {train_mae}\\n')\n    \n    # Evaluate on test data\n    if verbose:\n        print('Evaluating on test data...')\n    test_predictions = algo.test(testset)\n    test_rmse = accuracy.rmse(test_predictions, verbose=False)\n    test_mae = accuracy.mae(test_predictions, verbose=False)\n    \n    test_results['rmse'] = test_rmse\n    test_results['mae'] = test_mae\n    test_results['predictions'] = test_predictions\n    \n    if verbose:\n        print(f'Test RMSE: {test_rmse}')\n        print(f'Test MAE: {test_mae}\\n')\n    \n    if verbose:\n        print(f'Total time taken: {datetime.now() - start_time}')\n    \n    return train_results, test_results","metadata":{"execution":{"iopub.status.busy":"2024-07-12T20:04:58.114847Z","iopub.execute_input":"2024-07-12T20:04:58.115217Z","iopub.status.idle":"2024-07-12T20:04:58.125835Z","shell.execute_reply.started":"2024-07-12T20:04:58.115188Z","shell.execute_reply":"2024-07-12T20:04:58.124836Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Define hyperparameters for KNNBaseline\nknn_params = {\n    'k': 40,\n    'min_k': 1,\n    'sim_options': {\n        'name': 'pearson_baseline',\n        'user_based': False\n    }\n}\n\n# Initialize and run the KNNBaseline algorithm\ntrain_results_knn, test_results_knn = run_surprise_algorithm(KNNBaseline, knn_params, trainset, testset)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T20:05:04.823735Z","iopub.execute_input":"2024-07-12T20:05:04.824493Z","iopub.status.idle":"2024-07-12T20:05:32.157166Z","shell.execute_reply.started":"2024-07-12T20:05:04.824451Z","shell.execute_reply":"2024-07-12T20:05:32.156262Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Training the model...\nEstimating biases using als...\nComputing the pearson_baseline similarity matrix...\nDone computing similarity matrix.\nTraining completed. Time taken: 0:00:00.658482\n\nEvaluating on training data...\nTraining RMSE: 0.4062635072543094\nTraining MAE: 0.3073522748402174\n\nEvaluating on test data...\nTest RMSE: 0.9237660818560733\nTest MAE: 0.7229722085621993\n\nTotal time taken: 0:00:27.298315\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define hyperparameters for SVD\nsvd_params = {\n    'n_factors': 100,\n    'n_epochs': 50,\n    'lr_all': 0.005,\n    'reg_all': 0.02\n}\n\n# Initialize and run the SVD algorithm\ntrain_results_svd, test_results_svd = run_surprise_algorithm(SVD, svd_params, trainset, testset)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T20:05:43.213957Z","iopub.execute_input":"2024-07-12T20:05:43.214331Z","iopub.status.idle":"2024-07-12T20:05:46.619093Z","shell.execute_reply.started":"2024-07-12T20:05:43.214301Z","shell.execute_reply":"2024-07-12T20:05:46.618129Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Training the model...\nTraining completed. Time taken: 0:00:02.254334\n\nEvaluating on training data...\nTraining RMSE: 0.8408960165031524\nTraining MAE: 0.6663148858583093\n\nEvaluating on test data...\nTest RMSE: 0.9529774251658307\nTest MAE: 0.7535350804707042\n\nTotal time taken: 0:00:03.379350\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define hyperparameters for SVD\nsvd_params = {\n    'n_factors': 1000,\n    'n_epochs': 50,\n    'lr_all': 0.001,\n    'reg_all': 0.02\n}\n\n# Initialize and run the SVD algorithm\ntrain_results_svd, test_results_svd = run_surprise_algorithm(SVD, svd_params, trainset, testset)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T20:06:14.513817Z","iopub.execute_input":"2024-07-12T20:06:14.514663Z","iopub.status.idle":"2024-07-12T20:06:29.820202Z","shell.execute_reply.started":"2024-07-12T20:06:14.514628Z","shell.execute_reply":"2024-07-12T20:06:29.819297Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Training the model...\nTraining completed. Time taken: 0:00:14.103099\n\nEvaluating on training data...\nTraining RMSE: 0.41082959078969183\nTraining MAE: 0.3264556323585697\n\nEvaluating on test data...\nTest RMSE: 0.988778241557796\nTest MAE: 0.7868321855609476\n\nTotal time taken: 0:00:15.281207\n","output_type":"stream"}]},{"cell_type":"code","source":"import xgboost as xgb\nimport numpy as np\nfrom surprise import Dataset, Reader, KNNBaseline, SVD\nfrom surprise.model_selection import train_test_split\nfrom surprise import accuracy\nfrom datetime import datetime\n# Function to extract features for XGBoost\ndef extract_features(trainset):\n    \"\"\"\n    Extract features from the Surprise trainset for XGBoost.\n    \n    Args:\n    trainset: Surprise Trainset object\n    \n    Returns:\n    X, y: Feature matrix and target vector\n    \"\"\"\n    X = []\n    y = []\n    for uid, iid, rating in trainset.all_ratings():\n        X.append([int(uid), int(iid)])\n        y.append(rating)\n    return np.array(X), np.array(y)\n\n# Extract features from the trainset\nX_train, y_train = extract_features(trainset)\n\n# Train XGBoost model\nxgb_params = {\n    'objective': 'reg:squarederror',\n    'max_depth': 6,\n    'learning_rate': 0.1,\n    'n_estimators': 100\n}\nxgb_model = xgb.XGBRegressor(**xgb_params)\nxgb_model.fit(X_train, y_train)\n\n# Function to evaluate XGBoost model\ndef evaluate_xgboost(model, testset):\n    \"\"\"\n    Evaluate XGBoost model on the testset.\n    \n    Args:\n    model: Trained XGBoost model\n    testset: Surprise Testset object\n    \n    Returns:\n    rmse, mae: Evaluation metrics\n    \"\"\"\n    X_test = np.array([[int(uid), int(iid)] for (uid, iid, _) in testset])\n    y_test = np.array([rating for (_, _, rating) in testset])\n    y_pred = model.predict(X_test)\n    rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))\n    mae = np.mean(np.abs(y_test - y_pred))\n    return rmse, mae\n\n# Evaluate XGBoost model\ntest_rmse_xgb, test_mae_xgb = evaluate_xgboost(xgb_model, testset)\n\nprint(f'XGBoost Test RMSE: {test_rmse_xgb}')\nprint(f'XGBoost Test MAE: {test_mae_xgb}')","metadata":{"execution":{"iopub.status.busy":"2024-07-12T20:07:20.594646Z","iopub.execute_input":"2024-07-12T20:07:20.595514Z","iopub.status.idle":"2024-07-12T20:07:22.135733Z","shell.execute_reply.started":"2024-07-12T20:07:20.595482Z","shell.execute_reply":"2024-07-12T20:07:22.134999Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"XGBoost Test RMSE: 1.133272591913074\nXGBoost Test MAE: 0.9292148569726943\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}